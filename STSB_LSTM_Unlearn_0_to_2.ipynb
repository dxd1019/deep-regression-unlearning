{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This is a modified version of the official notebook, adapted to be fully compatible and runnable on Google Colab. Adjustments have been made to ensure smooth execution in the Colab environment."
      ],
      "metadata": {
        "id": "8Z_o7NP9u7gk"
      },
      "id": "8Z_o7NP9u7gk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install GitHub repo Packages"
      ],
      "metadata": {
        "id": "w5wd5HEgu-Bn"
      },
      "id": "w5wd5HEgu-Bn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eut-yxBK1Wdt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eut-yxBK1Wdt",
        "outputId": "9d53082e-e9ba-4482-92da-d46b7f544144"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deep-regression-unlearning'...\n",
            "remote: Enumerating objects: 78, done.\u001b[K\n",
            "remote: Counting objects: 100% (78/78), done.\u001b[K\n",
            "remote: Compressing objects: 100% (61/61), done.\u001b[K\n",
            "remote: Total 78 (delta 35), reused 43 (delta 16), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (78/78), 87.27 KiB | 3.23 MiB/s, done.\n",
            "Resolving deltas: 100% (35/35), done.\n",
            "/content/deep-regression-unlearning\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/dxd1019/deep-regression-unlearning\n",
        "\n",
        "%cd deep-regression-unlearning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wegq0TZ71ftN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wegq0TZ71ftN",
        "outputId": "ef9a7e7a-e463-47d7-8696-2301f7c61195"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyunpack\n",
            "  Downloading pyunpack-0.3-py2.py3-none-any.whl.metadata (863 bytes)\n",
            "Collecting patool\n",
            "  Downloading patool-4.0.0-py2.py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting easyprocess (from pyunpack)\n",
            "  Downloading EasyProcess-1.1-py3-none-any.whl.metadata (855 bytes)\n",
            "Collecting entrypoint2 (from pyunpack)\n",
            "  Downloading entrypoint2-1.1-py2.py3-none-any.whl.metadata (1.0 kB)\n",
            "Downloading pyunpack-0.3-py2.py3-none-any.whl (4.1 kB)\n",
            "Downloading patool-4.0.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.3/86.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading EasyProcess-1.1-py3-none-any.whl (8.7 kB)\n",
            "Downloading entrypoint2-1.1-py2.py3-none-any.whl (9.9 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=e77325a3ae633089d2bb6e57502fc317bcd4e7fc35d5c1ac3f304feb21d8954a\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, entrypoint2, easyprocess, pyunpack, patool\n",
            "Successfully installed easyprocess-1.1 entrypoint2-1.1 patool-4.0.0 pyunpack-0.3 wget-3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Wg3HK0te1lqh",
      "metadata": {
        "id": "Wg3HK0te1lqh"
      },
      "outputs": [],
      "source": [
        "import urllib.request"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hR-ia45IiccD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hR-ia45IiccD",
        "outputId": "9e4fc3b6-d8ca-453c-acac-ee1cff8b64c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AgeDB_AllCNN_0to30_forgetting.ipynb  LICENSE\t       script_download_data.py\n",
            "AgeDB_AllCNN_0to30_forgetting.py     metrics.py        STSB_LSTM_Unlearn_0_to_2.ipynb\n",
            "data_formatters\t\t\t     models.py\t       STSB_LSTM_Unlearn_0_to_2.py\n",
            "datasets.py\t\t\t     README.md\t       unlearn.py\n",
            "expt_settings\t\t\t     requirements.txt  utils.py\n",
            "[Errno 2] No such file or directory: 'deep-regression-unlearning'\n",
            "/content/deep-regression-unlearning\n"
          ]
        }
      ],
      "source": [
        "!ls\n",
        "%cd deep-regression-unlearning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fti_qAH-1obB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "fti_qAH-1obB",
        "outputId": "ee9b171d-d419-4450-fcae-e50f318c2f1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function WeakSet.__init__.<locals>._remove at 0x7b416270cfe0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/_weakrefset.py\", line 39, in _remove\n",
            "    def _remove(item, selfref=ref(self)):\n",
            "\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/content/deep-regression-unlearning/script_download_data.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mexpt_settings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExperimentConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/deep-regression-unlearning/expt_settings/configs.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdata_formatters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melectricity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_formatters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfavorita\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_formatters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraffic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/deep-regression-unlearning/data_formatters/electricity.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_formatters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mGenericDataFormatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_formatters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenericDataFormatter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0m_distributor_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m )\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclone\u001b[0m  \u001b[0;31m# noqa: E402\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m  \u001b[0;31m# noqa: E402\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInconsistentVersionWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_estimator_html_repr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_HTMLDocumentationLinkMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata_requests\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_MetadataRequester\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_routing_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvalidate_parameter_constraints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_joblib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata_routing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_bunch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBunch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_chunking\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgen_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_estimator_html_repr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_chunking.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInterval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/sparse/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_warnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_csr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_csc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/sparse/_base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m from ._sputils import (asmatrix, check_reshape_kwargs, check_shape,\n\u001b[0m\u001b[1;32m      6\u001b[0m                        \u001b[0mget_sum_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misdense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misscalarlike\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                        matrix, validateaxis,)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/sparse/_sputils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnp_long\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp_ulong\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/_lib/_util.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_array_api\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray_namespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_numpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxp_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/_lib/_array_api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray_api_compat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m from scipy._lib.array_api_compat import (\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mis_array_api_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/_lib/array_api_compat/numpy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# from numpy import * doesn't overwrite these builtin names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    356\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmatlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"f2py\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf2py\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf2py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf2py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"typing\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/f2py/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVisibleDeprecationWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mf2py2e\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdiagnose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/f2py/f2py2e.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcrackfortran\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcb_rules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/f2py/crackfortran.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;31m# As the needed functions cannot be determined by static inspection of the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;31m# code, it is safest to use import * pending a major refactoring of f2py.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mauxfuncs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msymbolic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/f2py/auxfuncs.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcfuncs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcfuncs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0merrmess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# %run script_download_data.py electricity ./data no"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iJj0khBh1qWc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJj0khBh1qWc",
        "outputId": "b1ee8cfb-0102-498b-f64b-a5b27e0e353d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b72a11e",
      "metadata": {
        "id": "3b72a11e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "import wget\n",
        "import zipfile\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.nn import functional as F\n",
        "from utils import clean_text\n",
        "from models import LSTMnetwork"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "924a107a",
      "metadata": {
        "id": "924a107a"
      },
      "source": [
        "## Define some helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a44827b1",
      "metadata": {
        "id": "a44827b1"
      },
      "outputs": [],
      "source": [
        "def training_step(model, batch, device):\n",
        "    sent1, sent2, labels = batch\n",
        "    sent1, sent2, labels = sent1.to(device), sent2.to(device), labels.to(device)\n",
        "    out, *_  = model(sent1, sent2)                  # Generate predictions\n",
        "    loss= F.mse_loss(out, labels) # Calculate loss\n",
        "    return loss\n",
        "\n",
        "def validation_step(model, batch, device):\n",
        "    sent1, sent2, labels = batch\n",
        "    sent1, sent2, labels = sent1.to(device), sent2.to(device), labels.to(device)\n",
        "    out, *_  = model(sent1, sent2)                    # Generate predictions\n",
        "    loss= F.mse_loss(out, labels)   # Calculate loss\n",
        "    return {'Loss': loss.detach()}\n",
        "\n",
        "def validation_epoch_end(model, outputs):\n",
        "    batch_losses = [x['Loss'] for x in outputs]\n",
        "    epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "    return {'Loss': epoch_loss.item()}\n",
        "\n",
        "def epoch_end(model, epoch, result):\n",
        "    print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}\".format(\n",
        "        epoch, result['lrs'][-1], result['train_loss'], result['Loss']))\n",
        "\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, val_df, device, batch_size = 256):\n",
        "    model.eval()\n",
        "    outputs = []\n",
        "\n",
        "    num_steps = len(val_df)//batch_size\n",
        "\n",
        "    for i in range(num_steps):\n",
        "        sent1 = torch.tensor(np.stack(val_df.iloc[i*batch_size:(i+1)*batch_size]['sentence1'])).float()\n",
        "        sent2 = torch.tensor(np.stack(val_df.iloc[i*batch_size:(i+1)*batch_size]['sentence2'])).float()\n",
        "        labels = torch.tensor(val_df.iloc[i*batch_size:(i+1)*batch_size]['score'].values)\n",
        "        batch = (sent1, sent2, labels)\n",
        "\n",
        "        outputs.append(validation_step(model, batch, device))\n",
        "\n",
        "    if len(val_df)%batch_size != 0:\n",
        "        sent1 = torch.tensor(np.stack(val_df.iloc[num_steps*batch_size:]['sentence1'])).float()\n",
        "        sent2 = torch.tensor(np.stack(val_df.iloc[num_steps*batch_size:]['sentence2'])).float()\n",
        "        labels = torch.tensor(val_df.iloc[num_steps*batch_size:]['score'].values)\n",
        "        batch = (sent1, sent2, labels)\n",
        "\n",
        "        outputs.append(validation_step(model, batch, device))\n",
        "\n",
        "    return validation_epoch_end(model, outputs)\n",
        "\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "def fit_one_cycle(epochs,  model, train_df, val_df, device, save_path, batch_size = 256):\n",
        "    best_loss = np.inf\n",
        "    torch.cuda.empty_cache()\n",
        "    history = []\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
        "\n",
        "    sched = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)\n",
        "    num_steps = len(train_df)//batch_size\n",
        "\n",
        "    #for\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        lrs = []\n",
        "        for i in range(num_steps):\n",
        "            sent1 = torch.tensor(np.stack(train_df.iloc[i*batch_size:(i+1)*batch_size]['sentence1'])).float()\n",
        "            sent2 = torch.tensor(np.stack(train_df.iloc[i*batch_size:(i+1)*batch_size]['sentence2'])).float()\n",
        "            labels = torch.tensor(train_df.iloc[i*batch_size:(i+1)*batch_size]['score'].values).float()\n",
        "            batch = (sent1, sent2, labels)\n",
        "            loss = training_step(model, batch, device)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            lrs.append(get_lr(optimizer))\n",
        "        if len(train_df)%batch_size != 0:\n",
        "            sent1 = torch.tensor(np.stack(train_df.iloc[num_steps*batch_size:]['sentence1'])).float()\n",
        "            sent2 = torch.tensor(np.stack(train_df.iloc[num_steps*batch_size:]['sentence2'])).float()\n",
        "            labels = torch.tensor(train_df.iloc[num_steps*batch_size:]['score'].values).float()\n",
        "            batch = (sent1, sent2, labels)\n",
        "            loss = training_step(model, batch, device)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            lrs.append(get_lr(optimizer))\n",
        "\n",
        "\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_df, device, batch_size)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        result['lrs'] = lrs\n",
        "        epoch_end(model, epoch, result)\n",
        "        history.append(result)\n",
        "        sched.step(result['Loss'])\n",
        "        if best_loss > result['Loss']:\n",
        "            best_loss = result['Loss']\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0530992b",
      "metadata": {
        "id": "0530992b"
      },
      "outputs": [],
      "source": [
        "def fit_one_finetune_cycle(epochs,  model, train_df, val_df, lr, device, save_path, batch_size = 256):\n",
        "    best_loss = np.inf\n",
        "    torch.cuda.empty_cache()\n",
        "    history = []\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
        "\n",
        "    sched = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)\n",
        "    num_steps = len(train_df)//batch_size\n",
        "\n",
        "    #for\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        lrs = []\n",
        "        for i in range(num_steps):\n",
        "            sent1 = torch.tensor(np.stack(train_df.iloc[i*batch_size:(i+1)*batch_size]['sentence1'])).float()\n",
        "            sent2 = torch.tensor(np.stack(train_df.iloc[i*batch_size:(i+1)*batch_size]['sentence2'])).float()\n",
        "            labels = torch.tensor(train_df.iloc[i*batch_size:(i+1)*batch_size]['score'].values).float()\n",
        "            batch = (sent1, sent2, labels)\n",
        "            loss = training_step(model, batch, device)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            lrs.append(get_lr(optimizer))\n",
        "        if len(train_df)%batch_size != 0:\n",
        "            sent1 = torch.tensor(np.stack(train_df.iloc[num_steps*batch_size:]['sentence1'])).float()\n",
        "            sent2 = torch.tensor(np.stack(train_df.iloc[num_steps*batch_size:]['sentence2'])).float()\n",
        "            labels = torch.tensor(train_df.iloc[num_steps*batch_size:]['score'].values).float()\n",
        "            batch = (sent1, sent2, labels)\n",
        "            loss = training_step(model, batch, device)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            lrs.append(get_lr(optimizer))\n",
        "\n",
        "\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_df, device, batch_size)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        result['lrs'] = lrs\n",
        "        epoch_end(model, epoch, result)\n",
        "        history.append(result)\n",
        "        sched.step(result['Loss'])\n",
        "        if best_loss > result['Loss']:\n",
        "            best_loss = result['Loss']\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41b683e4",
      "metadata": {
        "id": "41b683e4"
      },
      "outputs": [],
      "source": [
        "def attention(x):\n",
        "        \"\"\"\n",
        "        Taken from https://github.com/szagoruyko/attention-transfer\n",
        "        :param x = activations\n",
        "        \"\"\"\n",
        "        return F.normalize(x.pow(2).mean(1).view(x.size(0), -1))\n",
        "\n",
        "\n",
        "def attention_diff(x, y):\n",
        "    \"\"\"\n",
        "    Taken from https://github.com/szagoruyko/attention-transfer\n",
        "    :param x = activations\n",
        "    :param y = activations\n",
        "    \"\"\"\n",
        "    return (attention(x) - attention(y)).pow(2).mean()\n",
        "\n",
        "\n",
        "\n",
        "def forget_loss(model_output, model_activations, proxy_output, proxy_activations, mask):\n",
        "\n",
        "    loss = F.mse_loss(model_output[mask], proxy_output[mask])\n",
        "    if AT_beta > 0:\n",
        "        at_loss = 0\n",
        "        for i in range(len(proxy_activations)):\n",
        "            at_loss = at_loss + AT_beta * attention_diff(model_activations[i][mask], proxy_activations[i][mask])\n",
        "    else:\n",
        "        at_loss = 0\n",
        "\n",
        "    total_loss = loss + at_loss\n",
        "\n",
        "    return total_loss\n",
        "\n",
        "\n",
        "\n",
        "def fit_one_forget_cycle(epochs,  model, proxy_model, train_df, val_df, lr, device, save_path, batch_size = 256):\n",
        "    best_loss = np.inf\n",
        "    torch.cuda.empty_cache()\n",
        "    history = []\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
        "\n",
        "    sched = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)\n",
        "    num_steps = len(train_df)//batch_size\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        lrs = []\n",
        "        #for batch in train_loader:\n",
        "        for i in range(num_steps):\n",
        "            sent1 = torch.tensor(np.stack(train_df.iloc[i*batch_size:(i+1)*batch_size]['sentence1'])).float()\n",
        "            sent2 = torch.tensor(np.stack(train_df.iloc[i*batch_size:(i+1)*batch_size]['sentence2'])).float()\n",
        "            labels = torch.tensor(train_df.iloc[i*batch_size:(i+1)*batch_size]['score'].values).float()\n",
        "            ulabels = torch.tensor(train_df.iloc[i*batch_size:(i+1)*batch_size]['forget'].values)\n",
        "\n",
        "            sent1, sent2, labels, ulabels = sent1.to(device), sent2.to(device), labels.to(device), ulabels.to(device)\n",
        "\n",
        "            model_out, *model_activations = model(sent1, sent2)\n",
        "            with torch.no_grad():\n",
        "                proxy_out, *proxy_activations = proxy_model(sent1, sent2)\n",
        "\n",
        "\n",
        "            label_loss = 0\n",
        "            if ulabels.sum() < len(ulabels):\n",
        "                mask = (ulabels == 0)\n",
        "                r_model_out = model_out[mask]\n",
        "                r_labels = labels[mask]\n",
        "                label_loss = F.mse_loss(r_model_out, r_labels)\n",
        "\n",
        "            proxy_loss = 0\n",
        "            if ulabels.sum() > 0:\n",
        "                mask = (ulabels == 1)\n",
        "                proxy_loss = forget_loss(model_out, model_activations, proxy_out, proxy_activations, mask)\n",
        "\n",
        "            coeff = ulabels.sum()/len(ulabels)\n",
        "            loss = coeff*proxy_loss + (1-coeff)*label_loss\n",
        "\n",
        "            ######\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            lrs.append(get_lr(optimizer))\n",
        "\n",
        "        if len(train_df)%batch_size != 0:\n",
        "            sent1 = torch.tensor(np.stack(train_df.iloc[num_steps*batch_size:]['sentence1'])).float()\n",
        "            sent2 = torch.tensor(np.stack(train_df.iloc[num_steps*batch_size:]['sentence2'])).float()\n",
        "            labels = torch.tensor(train_df.iloc[num_steps*batch_size:]['score'].values).float()\n",
        "            ulabels = torch.tensor(train_df.iloc[num_steps*batch_size:]['forget'].values)\n",
        "\n",
        "            sent1, sent2, labels, ulabels = sent1.to(device), sent2.to(device), labels.to(device), ulabels.to(device)\n",
        "\n",
        "            model_out, *model_activations = model(sent1, sent2)\n",
        "            with torch.no_grad():\n",
        "                proxy_out, *proxy_activations = proxy_model(sent1, sent2)\n",
        "\n",
        "\n",
        "            label_loss = 0\n",
        "            if ulabels.sum() < len(ulabels):\n",
        "                mask = (ulabels == 0)\n",
        "                r_model_out = model_out[mask]\n",
        "                r_labels = labels[mask]\n",
        "                label_loss = F.mse_loss(r_model_out, r_labels)\n",
        "\n",
        "            proxy_loss = 0\n",
        "            if ulabels.sum() > 0:\n",
        "                mask = (ulabels == 1)\n",
        "                proxy_loss = forget_loss(model_out, model_activations, proxy_out, proxy_activations, mask)\n",
        "\n",
        "            coeff = ulabels.sum()/len(ulabels)\n",
        "            loss = coeff*proxy_loss + (1-coeff)*label_loss\n",
        "\n",
        "            ######\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            lrs.append(get_lr(optimizer))\n",
        "\n",
        "\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_df, device)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        result['lrs'] = lrs\n",
        "        epoch_end(model, epoch, result)\n",
        "        history.append(result)\n",
        "        #sched.step(result['Loss'])\n",
        "        #if best_loss > result['Loss']:\n",
        "        #    best_loss = result['Loss']\n",
        "        #    torch.save(model.state_dict(), save_path)\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c619d91c",
      "metadata": {
        "id": "c619d91c"
      },
      "outputs": [],
      "source": [
        "text_embedding_dimension = 300\n",
        "\n",
        "def text_embed(words):\n",
        "\n",
        "    unknown_indices = []\n",
        "    mean = np.zeros(text_embedding_dimension)\n",
        "\n",
        "    for i in range(len(words)):\n",
        "        if words[i] in embeddings_index_300 and embeddings_index_300[ words[i] ].shape == (300, ):\n",
        "            words[i] = embeddings_index_300[ words[i] ]\n",
        "            mean += words[i]\n",
        "        else:\n",
        "            unknown_indices.append(i)\n",
        "\n",
        "    mean /= max(len(words)-len(unknown_indices), 1)\n",
        "\n",
        "    # unknown words in the text are represented using the mean of the known words\n",
        "    for i in unknown_indices:\n",
        "        words[i] = mean\n",
        "    return words\n",
        "\n",
        "def pad(x, max_len = 10):\n",
        "    if len(x) >= max_len:\n",
        "        return x[:10]\n",
        "    zeros = [np.zeros(text_embedding_dimension)]*(max_len - len(x))\n",
        "    return zeros + x\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36c92dd4",
      "metadata": {
        "id": "36c92dd4"
      },
      "source": [
        "## Get GLOVE Word embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fa7b4a9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fa7b4a9",
        "outputId": "b7add2a2-0843-4577-c71e-50bdc1394bc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and extracting GloVe word embeddings...\n",
            "\n",
            "Completed!\n"
          ]
        }
      ],
      "source": [
        "print(\"Downloading and extracting GloVe word embeddings...\")\n",
        "data_file = \"./glove.840B.300d.zip\"\n",
        "wget.download(\"http://nlp.stanford.edu/data/glove.840B.300d.zip\", out=data_file)\n",
        "with zipfile.ZipFile(data_file) as zip_ref:\n",
        "    zip_ref.extractall('./glove')\n",
        "os.remove(data_file)\n",
        "print(\"\\nCompleted!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24ba7212",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24ba7212",
        "outputId": "9d33f7ef-09de-46bd-d1c2-f3c314d3f79b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-3ba7d9c1b092>:7: DeprecationWarning: string or file could not be read to its end due to unmatched data; this will raise a ValueError in the future.\n",
            "  coefs = np.fromstring(coefs, \"f\", sep=\" \")\n"
          ]
        }
      ],
      "source": [
        "path_to_glove_file = \"./glove/glove.840B.300d.txt\"\n",
        "\n",
        "embeddings_index_300 = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index_300[word] = coefs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d96820e5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d96820e5",
        "outputId": "de8940fd-2445-44f6-83e4-e3b58c55c409"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2195884 word vectors.\n"
          ]
        }
      ],
      "source": [
        "print(\"Found %s word vectors.\" % len(embeddings_index_300))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78b826fa",
      "metadata": {
        "id": "78b826fa"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "744d72db",
      "metadata": {
        "id": "744d72db"
      },
      "outputs": [],
      "source": [
        "columns = [\"genre\", \"filename\", \"year\", \"old_index\", \"score\", \"sentence1\", \"sentence2\"]\n",
        "\n",
        "train_df = pd.read_csv(\"./stsb_data/sts-train.tsv\", sep='\\t', header=None, names=columns, on_bad_lines='skip')\n",
        "val_df   = pd.read_csv(\"./stsb_data/sts-dev.tsv\", sep='\\t', header=None, names=columns, on_bad_lines='skip')\n",
        "test_df  = pd.read_csv(\"./stsb_data/sts-test.tsv\", sep='\\t', header=None, names=columns, quoting=3, on_bad_lines='skip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "S0z127JTr5vO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "S0z127JTr5vO",
        "outputId": "3e3a4a23-565d-40e0-de24-72277996672a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['genre', 'filename', 'year', 'old_index', 'score', 'sentence1',\n",
            "       'sentence2'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(test_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "baa4f766",
      "metadata": {
        "id": "baa4f766"
      },
      "outputs": [],
      "source": [
        "train_df.dropna(subset=['score'], inplace=True)\n",
        "val_df.dropna(subset=['score'], inplace=True)\n",
        "test_df.dropna(subset=['score'], inplace=True)\n",
        "\n",
        "# Drop rows with missing sentences\n",
        "train_df.dropna(subset=['sentence1', 'sentence2'], inplace=True)\n",
        "val_df.dropna(subset=['sentence1', 'sentence2'], inplace=True)\n",
        "test_df.dropna(subset=['sentence1', 'sentence2'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16b33a94",
      "metadata": {
        "id": "16b33a94"
      },
      "outputs": [],
      "source": [
        "train_df['sentence1'] = train_df['sentence1'].apply(lambda x: clean_text(x))\n",
        "train_df['sentence2'] = train_df['sentence2'].apply(lambda x: clean_text(x))\n",
        "\n",
        "val_df['sentence1'] = val_df['sentence1'].apply(lambda x: clean_text(x))\n",
        "val_df['sentence2'] = val_df['sentence2'].apply(lambda x: clean_text(x))\n",
        "\n",
        "test_df['sentence1'] = test_df['sentence1'].apply(lambda x: clean_text(x))\n",
        "test_df['sentence2'] = test_df['sentence2'].apply(lambda x: clean_text(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcbbe74a",
      "metadata": {
        "id": "bcbbe74a"
      },
      "outputs": [],
      "source": [
        "train_df['sentence1'] = train_df['sentence1'].apply(lambda words: text_embed(words))\n",
        "train_df['sentence2'] = train_df['sentence2'].apply(lambda words: text_embed(words))\n",
        "\n",
        "val_df['sentence1'] = val_df['sentence1'].apply(lambda words: text_embed(words))\n",
        "val_df['sentence2'] = val_df['sentence2'].apply(lambda words: text_embed(words))\n",
        "\n",
        "test_df['sentence1'] = test_df['sentence1'].apply(lambda words: text_embed(words))\n",
        "test_df['sentence2'] = test_df['sentence2'].apply(lambda words: text_embed(words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac57e5f6",
      "metadata": {
        "id": "ac57e5f6"
      },
      "outputs": [],
      "source": [
        "train_df['sentence1'] = train_df['sentence1'].apply(lambda words: pad(words))\n",
        "train_df['sentence2'] = train_df['sentence2'].apply(lambda words: pad(words))\n",
        "\n",
        "val_df['sentence1'] = val_df['sentence1'].apply(lambda words: pad(words))\n",
        "val_df['sentence2'] = val_df['sentence2'].apply(lambda words: pad(words))\n",
        "\n",
        "test_df['sentence1'] = test_df['sentence1'].apply(lambda words: pad(words))\n",
        "test_df['sentence2'] = test_df['sentence2'].apply(lambda words: pad(words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff0a35bf",
      "metadata": {
        "id": "ff0a35bf"
      },
      "outputs": [],
      "source": [
        "train_df = train_df.sample(frac = 1, random_state = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd8b997c",
      "metadata": {
        "id": "cd8b997c"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bvqRKabp3JNg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvqRKabp3JNg",
        "outputId": "999d2323-ada7-43d7-8675-51bef8f9af3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0], last_lr: 0.01000, train_loss: 3.4218, val_loss: 2.2629\n",
            "Epoch [1], last_lr: 0.01000, train_loss: 2.1209, val_loss: 2.2767\n",
            "Epoch [2], last_lr: 0.01000, train_loss: 2.0348, val_loss: 2.2872\n",
            "Epoch [3], last_lr: 0.01000, train_loss: 1.9412, val_loss: 2.3165\n",
            "Epoch [4], last_lr: 0.01000, train_loss: 1.8931, val_loss: 2.3201\n",
            "Epoch [5], last_lr: 0.01000, train_loss: 1.8103, val_loss: 2.3735\n",
            "Epoch [6], last_lr: 0.01000, train_loss: 1.7160, val_loss: 2.4143\n",
            "Epoch [7], last_lr: 0.01000, train_loss: 1.6323, val_loss: 2.4227\n",
            "Epoch [8], last_lr: 0.01000, train_loss: 1.4831, val_loss: 2.4118\n",
            "Epoch [9], last_lr: 0.01000, train_loss: 1.3505, val_loss: 2.4400\n",
            "Epoch [10], last_lr: 0.01000, train_loss: 1.2245, val_loss: 2.4757\n",
            "Epoch [11], last_lr: 0.01000, train_loss: 1.1064, val_loss: 2.4871\n",
            "Epoch [12], last_lr: 0.00100, train_loss: 0.9621, val_loss: 2.7062\n",
            "Epoch [13], last_lr: 0.00100, train_loss: 0.8445, val_loss: 2.8071\n",
            "Epoch [14], last_lr: 0.00100, train_loss: 0.8097, val_loss: 2.8141\n",
            "Epoch [15], last_lr: 0.00100, train_loss: 0.7976, val_loss: 2.8020\n",
            "Epoch [16], last_lr: 0.00100, train_loss: 0.7618, val_loss: 2.7965\n",
            "Epoch [17], last_lr: 0.00100, train_loss: 0.7403, val_loss: 2.7908\n",
            "Epoch [18], last_lr: 0.00100, train_loss: 0.7241, val_loss: 2.7972\n",
            "Epoch [19], last_lr: 0.00100, train_loss: 0.7186, val_loss: 2.8053\n",
            "Epoch [20], last_lr: 0.00100, train_loss: 0.6959, val_loss: 2.8366\n",
            "Epoch [21], last_lr: 0.00100, train_loss: 0.6731, val_loss: 2.8110\n",
            "Epoch [22], last_lr: 0.00100, train_loss: 0.6632, val_loss: 2.8239\n",
            "Epoch [23], last_lr: 0.00010, train_loss: 0.6354, val_loss: 2.8141\n",
            "Epoch [24], last_lr: 0.00010, train_loss: 0.6341, val_loss: 2.7938\n",
            "Epoch [25], last_lr: 0.00010, train_loss: 0.6374, val_loss: 2.8066\n",
            "Epoch [26], last_lr: 0.00010, train_loss: 0.6211, val_loss: 2.8074\n",
            "Epoch [27], last_lr: 0.00010, train_loss: 0.6381, val_loss: 2.7981\n",
            "Epoch [28], last_lr: 0.00010, train_loss: 0.6315, val_loss: 2.8051\n",
            "Epoch [29], last_lr: 0.00010, train_loss: 0.6113, val_loss: 2.8068\n",
            "Epoch [30], last_lr: 0.00010, train_loss: 0.6092, val_loss: 2.8075\n",
            "Epoch [31], last_lr: 0.00010, train_loss: 0.6191, val_loss: 2.8181\n",
            "Epoch [32], last_lr: 0.00010, train_loss: 0.6322, val_loss: 2.8092\n",
            "Epoch [33], last_lr: 0.00010, train_loss: 0.6186, val_loss: 2.8098\n",
            "Epoch [34], last_lr: 0.00001, train_loss: 0.6205, val_loss: 2.8078\n",
            "Epoch [35], last_lr: 0.00001, train_loss: 0.6063, val_loss: 2.8079\n",
            "Epoch [36], last_lr: 0.00001, train_loss: 0.6117, val_loss: 2.8078\n",
            "Epoch [37], last_lr: 0.00001, train_loss: 0.6061, val_loss: 2.8093\n",
            "Epoch [38], last_lr: 0.00001, train_loss: 0.6173, val_loss: 2.8113\n",
            "Epoch [39], last_lr: 0.00001, train_loss: 0.6118, val_loss: 2.8129\n",
            "Epoch [40], last_lr: 0.00001, train_loss: 0.6304, val_loss: 2.8133\n",
            "Epoch [41], last_lr: 0.00001, train_loss: 0.6026, val_loss: 2.8141\n",
            "Epoch [42], last_lr: 0.00001, train_loss: 0.6069, val_loss: 2.8148\n",
            "Epoch [43], last_lr: 0.00001, train_loss: 0.6192, val_loss: 2.8143\n",
            "Epoch [44], last_lr: 0.00001, train_loss: 0.6221, val_loss: 2.8140\n",
            "Epoch [45], last_lr: 0.00000, train_loss: 0.6114, val_loss: 2.8138\n",
            "Epoch [46], last_lr: 0.00000, train_loss: 0.6111, val_loss: 2.8140\n",
            "Epoch [47], last_lr: 0.00000, train_loss: 0.6158, val_loss: 2.8142\n",
            "Epoch [48], last_lr: 0.00000, train_loss: 0.6317, val_loss: 2.8141\n",
            "Epoch [49], last_lr: 0.00000, train_loss: 0.6212, val_loss: 2.8141\n",
            "Epoch [50], last_lr: 0.00000, train_loss: 0.6195, val_loss: 2.8141\n",
            "Epoch [51], last_lr: 0.00000, train_loss: 0.6066, val_loss: 2.8142\n",
            "Epoch [52], last_lr: 0.00000, train_loss: 0.6022, val_loss: 2.8141\n",
            "Epoch [53], last_lr: 0.00000, train_loss: 0.6248, val_loss: 2.8140\n",
            "Epoch [54], last_lr: 0.00000, train_loss: 0.6205, val_loss: 2.8139\n",
            "Epoch [55], last_lr: 0.00000, train_loss: 0.6181, val_loss: 2.8138\n",
            "Epoch [56], last_lr: 0.00000, train_loss: 0.6117, val_loss: 2.8138\n",
            "Epoch [57], last_lr: 0.00000, train_loss: 0.6181, val_loss: 2.8138\n",
            "Epoch [58], last_lr: 0.00000, train_loss: 0.6240, val_loss: 2.8138\n",
            "Epoch [59], last_lr: 0.00000, train_loss: 0.6198, val_loss: 2.8138\n",
            "Epoch [60], last_lr: 0.00000, train_loss: 0.6129, val_loss: 2.8138\n",
            "Epoch [61], last_lr: 0.00000, train_loss: 0.6110, val_loss: 2.8138\n",
            "Epoch [62], last_lr: 0.00000, train_loss: 0.6062, val_loss: 2.8138\n",
            "Epoch [63], last_lr: 0.00000, train_loss: 0.6163, val_loss: 2.8138\n",
            "Epoch [64], last_lr: 0.00000, train_loss: 0.6199, val_loss: 2.8138\n",
            "Epoch [65], last_lr: 0.00000, train_loss: 0.6046, val_loss: 2.8138\n",
            "Epoch [66], last_lr: 0.00000, train_loss: 0.6190, val_loss: 2.8138\n",
            "Epoch [67], last_lr: 0.00000, train_loss: 0.6089, val_loss: 2.8138\n",
            "Epoch [68], last_lr: 0.00000, train_loss: 0.6169, val_loss: 2.8138\n",
            "Epoch [69], last_lr: 0.00000, train_loss: 0.6155, val_loss: 2.8138\n",
            "Epoch [70], last_lr: 0.00000, train_loss: 0.6083, val_loss: 2.8138\n",
            "Epoch [71], last_lr: 0.00000, train_loss: 0.6284, val_loss: 2.8138\n",
            "Epoch [72], last_lr: 0.00000, train_loss: 0.6187, val_loss: 2.8138\n",
            "Epoch [73], last_lr: 0.00000, train_loss: 0.6123, val_loss: 2.8138\n",
            "Epoch [74], last_lr: 0.00000, train_loss: 0.6167, val_loss: 2.8138\n",
            "Epoch [75], last_lr: 0.00000, train_loss: 0.6243, val_loss: 2.8138\n",
            "Epoch [76], last_lr: 0.00000, train_loss: 0.5994, val_loss: 2.8138\n",
            "Epoch [77], last_lr: 0.00000, train_loss: 0.6200, val_loss: 2.8138\n",
            "Epoch [78], last_lr: 0.00000, train_loss: 0.6159, val_loss: 2.8138\n",
            "Epoch [79], last_lr: 0.00000, train_loss: 0.6234, val_loss: 2.8138\n",
            "Epoch [80], last_lr: 0.00000, train_loss: 0.6122, val_loss: 2.8138\n",
            "Epoch [81], last_lr: 0.00000, train_loss: 0.6217, val_loss: 2.8138\n",
            "Epoch [82], last_lr: 0.00000, train_loss: 0.6020, val_loss: 2.8138\n",
            "Epoch [83], last_lr: 0.00000, train_loss: 0.6091, val_loss: 2.8138\n",
            "Epoch [84], last_lr: 0.00000, train_loss: 0.6048, val_loss: 2.8138\n",
            "Epoch [85], last_lr: 0.00000, train_loss: 0.6229, val_loss: 2.8138\n",
            "Epoch [86], last_lr: 0.00000, train_loss: 0.6028, val_loss: 2.8138\n",
            "Epoch [87], last_lr: 0.00000, train_loss: 0.6172, val_loss: 2.8138\n",
            "Epoch [88], last_lr: 0.00000, train_loss: 0.6199, val_loss: 2.8138\n",
            "Epoch [89], last_lr: 0.00000, train_loss: 0.6244, val_loss: 2.8138\n",
            "Epoch [90], last_lr: 0.00000, train_loss: 0.6292, val_loss: 2.8138\n",
            "Epoch [91], last_lr: 0.00000, train_loss: 0.6256, val_loss: 2.8138\n",
            "Epoch [92], last_lr: 0.00000, train_loss: 0.6025, val_loss: 2.8138\n",
            "Epoch [93], last_lr: 0.00000, train_loss: 0.6247, val_loss: 2.8138\n",
            "Epoch [94], last_lr: 0.00000, train_loss: 0.6158, val_loss: 2.8138\n",
            "Epoch [95], last_lr: 0.00000, train_loss: 0.6094, val_loss: 2.8138\n",
            "Epoch [96], last_lr: 0.00000, train_loss: 0.6138, val_loss: 2.8138\n",
            "Epoch [97], last_lr: 0.00000, train_loss: 0.6208, val_loss: 2.8138\n",
            "Epoch [98], last_lr: 0.00000, train_loss: 0.6197, val_loss: 2.8138\n",
            "Epoch [99], last_lr: 0.00000, train_loss: 0.6261, val_loss: 2.8138\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# Dynamically select device\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Ensure the directory exists\n",
        "os.makedirs(\"saved_models\", exist_ok=True)\n",
        "\n",
        "model = LSTMnetwork(text_embedding_dimension = text_embedding_dimension).to(device)\n",
        "epochs = 100\n",
        "save_path = \"saved_models/LSTM_STSB_100epochs.pt\"\n",
        "history = fit_one_cycle(epochs, model, train_df, val_df, device = device, save_path = save_path)\n",
        "model.load_state_dict(torch.load(save_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e95014d9",
      "metadata": {
        "id": "e95014d9"
      },
      "source": [
        "## Creating the forget and retain sets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4fa3fb5",
      "metadata": {
        "id": "b4fa3fb5"
      },
      "outputs": [],
      "source": [
        "train_df_retain = train_df[train_df['score'] >= 2]\n",
        "val_df_retain = val_df[val_df['score'] >= 2]\n",
        "test_df_retain = test_df[test_df['score'] >= 2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3OPyRs9K89qL",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OPyRs9K89qL",
        "outputId": "9df83de8-ea50-4993-90af-6b76494d38ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test dataset size: 1095\n",
            "Test dataset size: 752\n",
            "<bound method NDFrame.head of               genre   filename      year  old_index  score  \\\n",
            "0     main-captions     MSRvid  2012test         24    2.5   \n",
            "1     main-captions     MSRvid  2012test         33    3.6   \n",
            "2     main-captions     MSRvid  2012test         45    5.0   \n",
            "3     main-captions     MSRvid  2012test         63    4.2   \n",
            "4     main-captions     MSRvid  2012test         66    1.5   \n",
            "...             ...        ...       ...        ...    ...   \n",
            "1090      main-news  headlines      2015       1438    0.4   \n",
            "1091      main-news  headlines      2015       1454    1.4   \n",
            "1092      main-news  headlines      2015       1456    4.8   \n",
            "1093      main-news  headlines      2015       1463    4.4   \n",
            "1094      main-news  headlines      2015       1482    5.0   \n",
            "\n",
            "                                              sentence1  \\\n",
            "0     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
            "1     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
            "2     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
            "3     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
            "4     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
            "...                                                 ...   \n",
            "1090  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
            "1091  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
            "1092  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
            "1093  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
            "1094  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
            "\n",
            "                                              sentence2  \n",
            "0     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
            "1     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
            "2     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
            "3     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
            "4     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
            "...                                                 ...  \n",
            "1090  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
            "1091  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
            "1092  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
            "1093  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
            "1094  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
            "\n",
            "[1095 rows x 7 columns]>\n"
          ]
        }
      ],
      "source": [
        "print(f\"Test dataset size: {len(test_df)}\")\n",
        "print(f\"Test dataset size: {len(test_df_retain)}\")\n",
        "print(test_df.head)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "beb1c7f6",
      "metadata": {
        "id": "beb1c7f6"
      },
      "outputs": [],
      "source": [
        "train_df_forget = train_df[train_df['score'] < 2]\n",
        "val_df_forget = val_df[val_df['score'] < 2]\n",
        "test_df_forget = test_df[test_df['score'] < 2]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4b8fe69",
      "metadata": {
        "id": "e4b8fe69"
      },
      "source": [
        "## Retraining the model from scratch on Retain Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6581b7f4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6581b7f4",
        "outputId": "b97d0da7-a423-44ca-8c08-2e1d322b690b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0], last_lr: 0.01000, train_loss: 5.1796, val_loss: 1.0471\n",
            "Epoch [1], last_lr: 0.01000, train_loss: 1.2543, val_loss: 0.7756\n",
            "Epoch [2], last_lr: 0.01000, train_loss: 0.8972, val_loss: 0.7321\n",
            "Epoch [3], last_lr: 0.01000, train_loss: 0.7816, val_loss: 0.7504\n",
            "Epoch [4], last_lr: 0.01000, train_loss: 0.7462, val_loss: 0.7945\n",
            "Epoch [5], last_lr: 0.01000, train_loss: 0.7246, val_loss: 0.7950\n",
            "Epoch [6], last_lr: 0.01000, train_loss: 0.7015, val_loss: 0.7780\n",
            "Epoch [7], last_lr: 0.01000, train_loss: 0.6921, val_loss: 0.7643\n",
            "Epoch [8], last_lr: 0.01000, train_loss: 0.6813, val_loss: 0.7745\n",
            "Epoch [9], last_lr: 0.01000, train_loss: 0.6735, val_loss: 0.7706\n",
            "Epoch [10], last_lr: 0.01000, train_loss: 0.6671, val_loss: 0.7734\n",
            "Epoch [11], last_lr: 0.01000, train_loss: 0.6459, val_loss: 0.7634\n",
            "Epoch [12], last_lr: 0.01000, train_loss: 0.6387, val_loss: 0.7800\n",
            "Epoch [13], last_lr: 0.01000, train_loss: 0.6254, val_loss: 0.7706\n",
            "Epoch [14], last_lr: 0.00100, train_loss: 0.6171, val_loss: 0.7553\n",
            "Epoch [15], last_lr: 0.00100, train_loss: 0.6118, val_loss: 0.7590\n",
            "Epoch [16], last_lr: 0.00100, train_loss: 0.6109, val_loss: 0.7559\n",
            "Epoch [17], last_lr: 0.00100, train_loss: 0.6033, val_loss: 0.7584\n",
            "Epoch [18], last_lr: 0.00100, train_loss: 0.5967, val_loss: 0.7576\n",
            "Epoch [19], last_lr: 0.00100, train_loss: 0.5837, val_loss: 0.7590\n",
            "Epoch [20], last_lr: 0.00100, train_loss: 0.5891, val_loss: 0.7596\n",
            "Epoch [21], last_lr: 0.00100, train_loss: 0.5916, val_loss: 0.7589\n",
            "Epoch [22], last_lr: 0.00100, train_loss: 0.5962, val_loss: 0.7582\n",
            "Epoch [23], last_lr: 0.00100, train_loss: 0.5863, val_loss: 0.7598\n",
            "Epoch [24], last_lr: 0.00100, train_loss: 0.5856, val_loss: 0.7620\n",
            "Epoch [25], last_lr: 0.00010, train_loss: 0.5936, val_loss: 0.7622\n",
            "Epoch [26], last_lr: 0.00010, train_loss: 0.5770, val_loss: 0.7624\n",
            "Epoch [27], last_lr: 0.00010, train_loss: 0.5915, val_loss: 0.7626\n",
            "Epoch [28], last_lr: 0.00010, train_loss: 0.5810, val_loss: 0.7629\n",
            "Epoch [29], last_lr: 0.00010, train_loss: 0.5747, val_loss: 0.7632\n",
            "Epoch [30], last_lr: 0.00010, train_loss: 0.5804, val_loss: 0.7634\n",
            "Epoch [31], last_lr: 0.00010, train_loss: 0.5709, val_loss: 0.7630\n",
            "Epoch [32], last_lr: 0.00010, train_loss: 0.5773, val_loss: 0.7629\n",
            "Epoch [33], last_lr: 0.00010, train_loss: 0.5815, val_loss: 0.7624\n",
            "Epoch [34], last_lr: 0.00010, train_loss: 0.5802, val_loss: 0.7625\n",
            "Epoch [35], last_lr: 0.00010, train_loss: 0.5676, val_loss: 0.7629\n",
            "Epoch [36], last_lr: 0.00001, train_loss: 0.5773, val_loss: 0.7630\n",
            "Epoch [37], last_lr: 0.00001, train_loss: 0.5842, val_loss: 0.7629\n",
            "Epoch [38], last_lr: 0.00001, train_loss: 0.5766, val_loss: 0.7629\n",
            "Epoch [39], last_lr: 0.00001, train_loss: 0.5712, val_loss: 0.7630\n",
            "Epoch [40], last_lr: 0.00001, train_loss: 0.5796, val_loss: 0.7631\n",
            "Epoch [41], last_lr: 0.00001, train_loss: 0.5810, val_loss: 0.7631\n",
            "Epoch [42], last_lr: 0.00001, train_loss: 0.5800, val_loss: 0.7631\n",
            "Epoch [43], last_lr: 0.00001, train_loss: 0.5842, val_loss: 0.7631\n",
            "Epoch [44], last_lr: 0.00001, train_loss: 0.5862, val_loss: 0.7631\n",
            "Epoch [45], last_lr: 0.00001, train_loss: 0.5758, val_loss: 0.7632\n",
            "Epoch [46], last_lr: 0.00001, train_loss: 0.5846, val_loss: 0.7633\n",
            "Epoch [47], last_lr: 0.00000, train_loss: 0.5812, val_loss: 0.7633\n",
            "Epoch [48], last_lr: 0.00000, train_loss: 0.5891, val_loss: 0.7633\n",
            "Epoch [49], last_lr: 0.00000, train_loss: 0.5757, val_loss: 0.7633\n",
            "Epoch [50], last_lr: 0.00000, train_loss: 0.5697, val_loss: 0.7633\n",
            "Epoch [51], last_lr: 0.00000, train_loss: 0.5780, val_loss: 0.7633\n",
            "Epoch [52], last_lr: 0.00000, train_loss: 0.5746, val_loss: 0.7633\n",
            "Epoch [53], last_lr: 0.00000, train_loss: 0.5710, val_loss: 0.7633\n",
            "Epoch [54], last_lr: 0.00000, train_loss: 0.5746, val_loss: 0.7633\n",
            "Epoch [55], last_lr: 0.00000, train_loss: 0.5771, val_loss: 0.7633\n",
            "Epoch [56], last_lr: 0.00000, train_loss: 0.5800, val_loss: 0.7634\n",
            "Epoch [57], last_lr: 0.00000, train_loss: 0.5890, val_loss: 0.7634\n",
            "Epoch [58], last_lr: 0.00000, train_loss: 0.5812, val_loss: 0.7634\n",
            "Epoch [59], last_lr: 0.00000, train_loss: 0.5796, val_loss: 0.7634\n",
            "Epoch [60], last_lr: 0.00000, train_loss: 0.5734, val_loss: 0.7634\n",
            "Epoch [61], last_lr: 0.00000, train_loss: 0.5824, val_loss: 0.7634\n",
            "Epoch [62], last_lr: 0.00000, train_loss: 0.5825, val_loss: 0.7634\n",
            "Epoch [63], last_lr: 0.00000, train_loss: 0.5836, val_loss: 0.7634\n",
            "Epoch [64], last_lr: 0.00000, train_loss: 0.5815, val_loss: 0.7634\n",
            "Epoch [65], last_lr: 0.00000, train_loss: 0.5920, val_loss: 0.7634\n",
            "Epoch [66], last_lr: 0.00000, train_loss: 0.5838, val_loss: 0.7634\n",
            "Epoch [67], last_lr: 0.00000, train_loss: 0.5754, val_loss: 0.7634\n",
            "Epoch [68], last_lr: 0.00000, train_loss: 0.5795, val_loss: 0.7634\n",
            "Epoch [69], last_lr: 0.00000, train_loss: 0.5846, val_loss: 0.7634\n",
            "Epoch [70], last_lr: 0.00000, train_loss: 0.5766, val_loss: 0.7634\n",
            "Epoch [71], last_lr: 0.00000, train_loss: 0.5850, val_loss: 0.7634\n",
            "Epoch [72], last_lr: 0.00000, train_loss: 0.5686, val_loss: 0.7634\n",
            "Epoch [73], last_lr: 0.00000, train_loss: 0.5803, val_loss: 0.7634\n",
            "Epoch [74], last_lr: 0.00000, train_loss: 0.5717, val_loss: 0.7634\n",
            "Epoch [75], last_lr: 0.00000, train_loss: 0.5714, val_loss: 0.7634\n",
            "Epoch [76], last_lr: 0.00000, train_loss: 0.5818, val_loss: 0.7634\n",
            "Epoch [77], last_lr: 0.00000, train_loss: 0.5817, val_loss: 0.7634\n",
            "Epoch [78], last_lr: 0.00000, train_loss: 0.5809, val_loss: 0.7634\n",
            "Epoch [79], last_lr: 0.00000, train_loss: 0.5748, val_loss: 0.7634\n",
            "Epoch [80], last_lr: 0.00000, train_loss: 0.5877, val_loss: 0.7634\n",
            "Epoch [81], last_lr: 0.00000, train_loss: 0.5776, val_loss: 0.7634\n",
            "Epoch [82], last_lr: 0.00000, train_loss: 0.5791, val_loss: 0.7634\n",
            "Epoch [83], last_lr: 0.00000, train_loss: 0.5748, val_loss: 0.7634\n",
            "Epoch [84], last_lr: 0.00000, train_loss: 0.5796, val_loss: 0.7634\n",
            "Epoch [85], last_lr: 0.00000, train_loss: 0.5623, val_loss: 0.7634\n",
            "Epoch [86], last_lr: 0.00000, train_loss: 0.5857, val_loss: 0.7634\n",
            "Epoch [87], last_lr: 0.00000, train_loss: 0.5788, val_loss: 0.7634\n",
            "Epoch [88], last_lr: 0.00000, train_loss: 0.5834, val_loss: 0.7634\n",
            "Epoch [89], last_lr: 0.00000, train_loss: 0.5850, val_loss: 0.7634\n",
            "Epoch [90], last_lr: 0.00000, train_loss: 0.5858, val_loss: 0.7634\n",
            "Epoch [91], last_lr: 0.00000, train_loss: 0.5767, val_loss: 0.7634\n",
            "Epoch [92], last_lr: 0.00000, train_loss: 0.5710, val_loss: 0.7634\n",
            "Epoch [93], last_lr: 0.00000, train_loss: 0.5835, val_loss: 0.7634\n",
            "Epoch [94], last_lr: 0.00000, train_loss: 0.5711, val_loss: 0.7634\n",
            "Epoch [95], last_lr: 0.00000, train_loss: 0.5667, val_loss: 0.7634\n",
            "Epoch [96], last_lr: 0.00000, train_loss: 0.5839, val_loss: 0.7634\n",
            "Epoch [97], last_lr: 0.00000, train_loss: 0.5794, val_loss: 0.7634\n",
            "Epoch [98], last_lr: 0.00000, train_loss: 0.5825, val_loss: 0.7634\n",
            "Epoch [99], last_lr: 0.00000, train_loss: 0.5836, val_loss: 0.7634\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "gold_model = LSTMnetwork(text_embedding_dimension=text_embedding_dimension).to(device)\n",
        "\n",
        "epochs = 100\n",
        "save_path = \"saved_models/LSTM_STSB_100epochs_0to2_retrained.pt\"\n",
        "history = fit_one_cycle(epochs, gold_model, train_df_retain, val_df_retain, device = device, save_path = save_path)\n",
        "gold_model.load_state_dict(torch.load(save_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "706b753b",
      "metadata": {
        "id": "706b753b"
      },
      "source": [
        "### Evaluate the retrained model on various cohorts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LhDAZMRH82Rq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhDAZMRH82Rq",
        "outputId": "8c1f75e8-5e89-43a2-b65f-959fa5b3c931"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test dataset size: 752\n"
          ]
        }
      ],
      "source": [
        "print(f\"Test dataset size: {len(test_df_retain)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56387ab7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56387ab7",
        "outputId": "96c47ac4-1e7e-4c8f-9ead-0abae73800b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Loss': 2.225020241226177}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# evaluate(model, test_df_retain, 'cuda')\n",
        "evaluate(model, test_df_retain, 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16bb9939",
      "metadata": {
        "id": "16bb9939",
        "outputId": "7a720b3e-a617-4cb3-b278-fb5e44a03aed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Loss': 2.225020241226177}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "# evaluate(model, test_df_forget, 'cuda')\n",
        "evaluate(model, test_df_retain, 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9dd8476",
      "metadata": {
        "id": "f9dd8476",
        "outputId": "b3168c94-2b2b-4f17-ffc5-20dba25cbfc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Loss': 2.225020241226177}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "# evaluate(gold_model, test_df_retain, 'cuda')\n",
        "evaluate(model, test_df_retain, 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e51de613",
      "metadata": {
        "id": "e51de613",
        "outputId": "ac537daf-4ca0-4082-bf4c-8662437e3e80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Loss': 2.225020241226177}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "# evaluate(gold_model, test_df_forget, 'cuda')\n",
        "evaluate(model, test_df_retain, 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72ce5e55",
      "metadata": {
        "id": "72ce5e55"
      },
      "source": [
        "## Finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5b988cd",
      "metadata": {
        "id": "c5b988cd",
        "outputId": "74c57674-a49e-4026-cf42-4b6fac0a8a73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0], last_lr: 0.00100, train_loss: 1.1413, val_loss: 0.9920\n",
            "Epoch [1], last_lr: 0.00100, train_loss: 0.7991, val_loss: 0.7721\n",
            "Epoch [2], last_lr: 0.00100, train_loss: 0.7599, val_loss: 0.7651\n",
            "Epoch [3], last_lr: 0.00100, train_loss: 0.7407, val_loss: 0.7562\n",
            "Epoch [4], last_lr: 0.00100, train_loss: 0.7423, val_loss: 0.7424\n",
            "CPU times: user 6.15 s, sys: 550 ms, total: 6.7 s\n",
            "Wall time: 7.22 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "%%time\n",
        "student_model = LSTMnetwork(text_embedding_dimension = text_embedding_dimension).to(device)\n",
        "student_model.load_state_dict(torch.load(\"saved_models/LSTM_STSB_100epochs.pt\"))\n",
        "epochs = 5\n",
        "save_path = \"saved_models/LSTM_STSB_5epochs_4to5_Finetune_Forget.pt\"\n",
        "history = fit_one_finetune_cycle(epochs, student_model, train_df_retain, val_df_retain, 0.001, device = device, save_path = save_path)\n",
        "student_model.load_state_dict(torch.load(save_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2952073d",
      "metadata": {
        "id": "2952073d",
        "outputId": "3f85eb31-7ca4-44da-b661-3b595aa11658",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Loss': 0.7120824645667595}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# evaluate(student_model, test_df_retain, 'cuda')\n",
        "evaluate(student_model, test_df_retain, 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c421e03",
      "metadata": {
        "id": "0c421e03",
        "outputId": "16c34127-c62c-45f7-bde2-a64d9742c743",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Loss': 0.7120824645667595}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# evaluate(student_model, test_df_forget, 'cuda')\n",
        "evaluate(student_model, test_df_retain, 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20853f1f",
      "metadata": {
        "id": "20853f1f"
      },
      "source": [
        "## Amnesiac Finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b8a0585",
      "metadata": {
        "id": "9b8a0585"
      },
      "outputs": [],
      "source": [
        "mean = train_df['score'].mean()\n",
        "sd = train_df['score'].std()\n",
        "\n",
        "random_preds = np.random.normal(loc=mean, scale=sd, size=(len(train_df[train_df['score'] < 2]),))\n",
        "\n",
        "amnesiac_finetune_df = train_df.copy()\n",
        "amnesiac_finetune_df.loc[amnesiac_finetune_df['score'] < 2, 'score'] = random_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c35e52c",
      "metadata": {
        "id": "2c35e52c",
        "outputId": "53263b47-8e34-4f6f-ef52-5179b9e199f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0], last_lr: 0.00100, train_loss: 1.5012, val_loss: 0.8694\n",
            "Epoch [1], last_lr: 0.00100, train_loss: 1.3398, val_loss: 0.7907\n",
            "Epoch [2], last_lr: 0.00100, train_loss: 1.3200, val_loss: 0.7780\n",
            "Epoch [3], last_lr: 0.00100, train_loss: 1.2971, val_loss: 0.7691\n",
            "Epoch [4], last_lr: 0.00100, train_loss: 1.2966, val_loss: 0.7703\n",
            "CPU times: user 10 s, sys: 843 ms, total: 10.9 s\n",
            "Wall time: 11.3 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "%%time\n",
        "student_model = LSTMnetwork(text_embedding_dimension = text_embedding_dimension).to(device)\n",
        "student_model.load_state_dict(torch.load(\"saved_models/LSTM_STSB_100epochs.pt\"))\n",
        "epochs = 5\n",
        "save_path = \"saved_models/LSTM_STSB_2epochs_Amnesiac_Finetune_Forget.pt\"\n",
        "history = fit_one_finetune_cycle(epochs, student_model, amnesiac_finetune_df, val_df_retain, 0.001, device = device, save_path = save_path)\n",
        "student_model.load_state_dict(torch.load(save_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "683eca0b",
      "metadata": {
        "id": "683eca0b",
        "outputId": "70c9034f-e016-458a-81e7-3340c145815d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Loss': 0.7337983449954232}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "# evaluate(student_model, test_df_retain, 'cuda')\n",
        "evaluate(student_model, test_df_retain, 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79517fae",
      "metadata": {
        "id": "79517fae",
        "outputId": "0f5e1f0c-de71-496d-ac44-ada7792c380b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Loss': 0.7337983449954232}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "# evaluate(student_model, test_df_forget, 'cuda')\n",
        "evaluate(student_model, test_df_retain, 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "215bb9e1",
      "metadata": {
        "id": "215bb9e1"
      },
      "source": [
        "## Blindspot Unlearning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7f20c7a",
      "metadata": {
        "id": "b7f20c7a"
      },
      "outputs": [],
      "source": [
        "u_train_df = train_df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca6e4e6f",
      "metadata": {
        "id": "ca6e4e6f"
      },
      "outputs": [],
      "source": [
        "u_train_df['forget'] = 0\n",
        "u_train_df.loc[u_train_df['score'] < 2, 'forget'] = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e667bf9a",
      "metadata": {
        "id": "e667bf9a"
      },
      "source": [
        "### Training the Blindspot model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84f6a8b9",
      "metadata": {
        "id": "84f6a8b9",
        "outputId": "859cecf5-ef7a-4f94-efe2-8a55062f28e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0], last_lr: 0.01000, train_loss: 3.7622, val_loss: 1.3992\n",
            "Epoch [1], last_lr: 0.01000, train_loss: 0.8490, val_loss: 0.7343\n",
            "Epoch [2], last_lr: 0.01000, train_loss: 0.7439, val_loss: 0.7814\n",
            "Epoch [3], last_lr: 0.01000, train_loss: 0.7170, val_loss: 0.7425\n",
            "Epoch [4], last_lr: 0.01000, train_loss: 0.7036, val_loss: 0.7633\n",
            "Epoch [5], last_lr: 0.01000, train_loss: 0.6868, val_loss: 0.7535\n",
            "Epoch [6], last_lr: 0.01000, train_loss: 0.6900, val_loss: 0.7506\n",
            "Epoch [7], last_lr: 0.01000, train_loss: 0.6806, val_loss: 0.7612\n",
            "Epoch [8], last_lr: 0.01000, train_loss: 0.6602, val_loss: 0.7554\n",
            "Epoch [9], last_lr: 0.01000, train_loss: 0.6518, val_loss: 0.7533\n",
            "CPU times: user 13.6 s, sys: 1.59 s, total: 15.2 s\n",
            "Wall time: 15.3 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "%%time\n",
        "# device = 'cuda'\n",
        "device = 'cpu'\n",
        "proxy_model = LSTMnetwork(text_embedding_dimension = text_embedding_dimension).to(device)\n",
        "epochs = 10\n",
        "save_path = \"saved_models/LSTM_STSB_blindspot.pt\"\n",
        "history = fit_one_cycle(epochs, proxy_model, train_df_retain, val_df_retain, device = device, save_path = save_path)\n",
        "proxy_model.load_state_dict(torch.load(save_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8b1d24f",
      "metadata": {
        "id": "f8b1d24f",
        "outputId": "02dc25f2-1713-423d-9f94-d285744f6fea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Loss': 0.7225442171665678}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "# evaluate(proxy_model, test_df_retain, 'cuda')\n",
        "evaluate(proxy_model, test_df_retain, 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7606e738",
      "metadata": {
        "id": "7606e738",
        "outputId": "6f4ba882-aba6-491e-e34a-5d95e75e6743",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Loss': 0.7225442171665678}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "# evaluate(proxy_model, test_df_forget, 'cuda')\n",
        "evaluate(proxy_model, test_df_retain, 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2550637",
      "metadata": {
        "id": "e2550637",
        "outputId": "3ecd676a-2f04-4540-9d9c-a04aa99a2d0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0], last_lr: 0.00100, train_loss: 1.2391, val_loss: 3.2372\n",
            "Epoch [1], last_lr: 0.00100, train_loss: 0.8674, val_loss: 3.6021\n",
            "Epoch [2], last_lr: 0.00100, train_loss: 0.7069, val_loss: 3.6510\n",
            "Epoch [3], last_lr: 0.00100, train_loss: 0.6053, val_loss: 3.6217\n",
            "Epoch [4], last_lr: 0.00100, train_loss: 0.5642, val_loss: 3.6158\n",
            "CPU times: user 13.6 s, sys: 1.15 s, total: 14.8 s\n",
            "Wall time: 14.9 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "%%time\n",
        "AT_beta = 50\n",
        "student_model = LSTMnetwork(text_embedding_dimension = text_embedding_dimension).to(device)\n",
        "student_model.load_state_dict(torch.load(\"saved_models/LSTM_STSB_100epochs.pt\"))\n",
        "epochs = 5\n",
        "save_path = \"saved_models/LSTM_STSB_unlearn.pt\"\n",
        "history = fit_one_forget_cycle(epochs, student_model, proxy_model,  u_train_df, val_df, lr = 0.001, device = device, save_path = save_path)\n",
        "student_model.load_state_dict(torch.load(save_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b5f314a",
      "metadata": {
        "id": "4b5f314a",
        "outputId": "0395da59-2852-4983-d5ce-7bb4be222786",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Loss': 0.7163172047360549}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "# evaluate(student_model, test_df_retain, 'cuda')\n",
        "evaluate(student_model, test_df_retain, 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a0a2633",
      "metadata": {
        "id": "2a0a2633",
        "outputId": "0a99b1fc-965f-49cf-8d14-114ae287dd91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Loss': 0.7163172047360549}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "# evaluate(student_model, test_df_forget, 'cuda')\n",
        "evaluate(student_model, test_df_retain, 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb568be7",
      "metadata": {
        "id": "cb568be7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43a3f94e",
      "metadata": {
        "id": "43a3f94e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}